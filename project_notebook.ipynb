{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('snlp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2ff9090dfdad0989f1bba43fdc84eca73f850cacb0ad7e457a2bb7d28546cc9f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# English - Alice in wonderland\n",
    "\n",
    "## Data preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import preprocessor\n",
    "preprocessor = reload(preprocessor)\n",
    "\n",
    "\n",
    "pp = preprocessor.Preprocessor(\"data/alice_in_wonderland.txt\", \"eng\")\n",
    "cleaned_corpus = pp.process()\n",
    "pp.split(cleaned_corpus)"
   ]
  },
  {
   "source": [
    "## Subword segmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentpiece\n",
    "sentpiece = reload(sentpiece)\n",
    "\n",
    "\n",
    "NUM_CHARS = 44\n",
    "TRAIN_DATA_PATH = \"data/eng_train.txt\"\n",
    "MODEL_NAME = \"eng_model_char\"\n",
    "SEG_DATA_PATH = \"en_s1.txt\"\n",
    "\n",
    "\n",
    "sentpiece.train_model(TRAIN_DATA_PATH, MODEL_NAME, NUM_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv $MODEL_NAME* models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentpiece.segmentation(TRAIN_DATA_PATH, MODEL_NAME, SEG_DATA_PATH)"
   ]
  },
  {
   "source": [
    "## Train LM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rm: cannot remove 'rnnlm/models/model': No such file or directory\n",
      "rm: cannot remove 'rnnlm/models/model.output.txt': No such file or directory\n",
      "debug mode: 2\n",
      "train file: data/eng_train.txt\n",
      "valid file: data/eng_test.txt\n",
      "class size: 9999\n",
      "Hidden layer size: 40\n",
      "BPTT: 3\n",
      "Rand seed: 1\n",
      "rnnlm file: model\n",
      "Starting training using file data/eng_train.txt\n",
      "Vocab size: 4119\n",
      "Words in train file: 24231\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:   0\tAlpha: 0.100000\t   TRAIN entropy: 9.3558    Words/sec: 540.6   VALID entropy: 8.1441\n",
      "Iter:   1\tAlpha: 0.100000\t   TRAIN entropy: 8.8022    Words/sec: 524.0   VALID entropy: 7.7922\n",
      "Iter:   2\tAlpha: 0.100000\t   TRAIN entropy: 8.4398    Words/sec: 530.1   VALID entropy: 7.6852\n",
      "Iter:   3\tAlpha: 0.100000\t   TRAIN entropy: 8.1320    Words/sec: 515.8   VALID entropy: 7.4599\n",
      "Iter:   4\tAlpha: 0.100000\t   TRAIN entropy: 7.8664    Words/sec: 617.0   VALID entropy: 7.3073\n",
      "Iter:   5\tAlpha: 0.100000\t   TRAIN entropy: 7.6337    Words/sec: 733.8   VALID entropy: 7.2368\n",
      "Iter:   6\tAlpha: 0.100000\t   TRAIN entropy: 7.4100    Words/sec: 1382.6   VALID entropy: 7.2403\n",
      "Iter:   7\tAlpha: 0.050000\t   TRAIN entropy: 7.3015    Words/sec: 1358.5   VALID entropy: 7.1158\n",
      "Iter:   8\tAlpha: 0.025000\t   TRAIN entropy: 7.1233    Words/sec: 808.7   VALID entropy: 7.0422\n",
      "Iter:   9\tAlpha: 0.012500\t   TRAIN entropy: 7.0329    Words/sec: 544.7   VALID entropy: 6.9855\n",
      "Iter:  10\tAlpha: 0.006250\t   TRAIN entropy: 6.9917    Words/sec: 539.5   VALID entropy: 6.9412\n",
      "Iter:  11\tAlpha: 0.003125\t   TRAIN entropy: 6.9756    Words/sec: 540.4   VALID entropy: 6.9059\n",
      "Iter:  12\tAlpha: 0.001563\t   TRAIN entropy: 6.9684    Words/sec: 525.3   VALID entropy: 6.8833\n",
      "Iter:  13\tAlpha: 0.000781\t   TRAIN entropy: 6.9641    Words/sec: 526.6   VALID entropy: 6.8716\n",
      "\n",
      "real\t9m54.016s\n",
      "user\t9m51.528s\n",
      "sys\t0m0.286s\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SEG_DATA_PATH = \"segmented_corpora/en_s1.txt\"\n",
    "\n",
    "!bash train_script.sh TRAIN_SEG_DATA_PATH \"data/eng_test.txt\" 40 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv model model.output.txt rnnlm/models/"
   ]
  },
  {
   "source": [
    "## Data generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_DATA_PATH = \"gen_data/eng_model_chr/\"\n",
    "\n",
    "!bash gen_script.sh GEN_DATA_PATH"
   ]
  },
  {
   "source": [
    "# Bengali"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}